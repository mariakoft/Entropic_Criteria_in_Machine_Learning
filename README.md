# Entropic_Criteria_in_Machine_Learning
An overview of the utilization of Information Theory in Machine Learning algorithms followed by 3 algorithm implementations and 3 discrete presentations of their results.

To ease navigation via projects, each implementation forms a unique repository;

--Classification using a MLP Neural Network based on "Minimazation of Error's Entropy", implemented in Python:
https://github.com/mariakoft/Classification_MLP_Shannon_Entropy_Cost_Function
Joined effort by me and George Balas.


--Clustering using Renyi's Entropy, implemented in R: 
https://github.com/mariakoft/Clustering_Renyi_Entropy
Joined effort by me and Anastasia Foudoyli.

--Multinomial Regretion using a MLP with a "Crossentropy baseed cost function",implemented in Matlab : https://github.com/mariakoft/SoftMax_Regression
Joined effort by me and Spyridon Dimitriadis.

Auth, 2017-2018
